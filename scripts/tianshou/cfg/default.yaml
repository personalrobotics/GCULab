# configuration file for training

seed: 5
cuda_deterministic: True
log_interval: 10               # How often to print training logs

env:
  id: OnlinePack-v1            # env name
  scheme: EMS                  # the scheme of generating candidate map: heightmap, EP, FC
  rot: True
  box_type: random
  container_size: [10, 10, 10]
  k_placement: 100             # number of candidate placements
  

train:
  algo: PPO
  clip_param: 0.3
  num_processes: 128
  num_steps: 6
  epoch: 500
  batch_size: 128
  step_per_epoch: 32768        # 2**15
  repeat_per_collect: 1
  gae_lambda: 0.96
  reward_type:                 # optional: "terminal", None
  gamma: 1                     # discount factor for rewards (default: 1)

opt:  # optimizer
  optimizer: Adam              # optimizer: Adam, RMSprop
  lr: 7e-5                     # learning rate (RMSprop7e-4, 1e-6, Adam7e-5)
  lr_decay: False              # use a linear schedule on the learning rate
  eps: 1e-5                    # epsilon (default: 1e-5)
  alpha: 0.99                  # RMSprop alpha (default: 0.99)
  
loss:
  entropy: 0.001               # entropy term coefficient (default: 0.01)
  value: 0.5                   # value loss coefficient (default: 0.5)

model:
  embed_dim: 128
  heads: 1
  num_layers: 4
  forward_expansion: 2
  dropout: 0

